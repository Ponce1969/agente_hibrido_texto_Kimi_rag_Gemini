# üöÄ Mejoras del Sistema RAG con Gemini y pgvector

## üìã Resumen de Cambios

Se han implementado mejoras significativas al sistema RAG (Retrieval-Augmented Generation) que utiliza Gemini para embeddings y PostgreSQL con pgvector para almacenamiento vectorial.

### ‚ú® Mejoras Implementadas

#### 1. **Aumento de Contexto (5 ‚Üí 10 chunks)**
- **Antes:** Top-5 chunks m√°s relevantes
- **Ahora:** Top-10 chunks m√°s relevantes
- **Beneficio:** Mayor cobertura de contexto para respuestas m√°s completas

#### 2. **Chunks M√°s Grandes (600 ‚Üí 1000 caracteres)**
- **Antes:** Chunks de 600 caracteres con overlap de 100
- **Ahora:** Chunks de 1000 caracteres con overlap de 150
- **Beneficio:** Menos fragmentaci√≥n, mejor coherencia del contexto

#### 3. **Metadatos para Filtrado Inteligente**
Nuevos campos agregados a cada chunk:
- `page_number`: N√∫mero de p√°gina del chunk
- `section_type`: Tipo de secci√≥n (chapter, introduction, etc.)
- `file_name`: Nombre original del archivo

**Beneficios:**
- Filtrado por p√°gina espec√≠fica
- B√∫squedas contextuales mejoradas
- Mejor trazabilidad del origen del contenido

---

## üèóÔ∏è Arquitectura Actualizada

### Componentes Modificados

#### 1. **Configuraci√≥n (`settings.py`)**
```python
embedding_chunk_size: int = 1000  # Antes: 600
embedding_chunk_overlap: int = 150  # Antes: 100
max_search_results: int = 10  # Antes: 5
```

#### 2. **Modelos de Datos (`embeddings_models.py`)**
```python
@dataclass(frozen=True)
class EmbeddingChunk:
    # ... campos existentes ...
    page_number: Optional[int] = None
    section_type: Optional[str] = None
    file_name: Optional[str] = None
```

#### 3. **Schema de PostgreSQL**
```sql
CREATE TABLE document_chunks (
    -- ... columnas existentes ...
    page_number INTEGER,
    section_type VARCHAR(100),
    file_name VARCHAR(500)
);

-- √çndices para mejor rendimiento
CREATE INDEX idx_document_chunks_page_number ON document_chunks(page_number);
CREATE INDEX idx_document_chunks_section_type ON document_chunks(section_type);
```

#### 4. **Repository (`embeddings_repository.py`)**
- `insert_chunks()`: Ahora inserta metadatos
- `search_top_k()`: Retorna metadatos en resultados
- Default `top_k` aumentado de 5 a 10

#### 5. **Adapter (`gemini_embeddings_adapter.py`)**
- `store_embedding()`: Acepta metadatos opcionales
- `search_similar()`: Default `top_k=10`
- `index_document()`: Genera chunks con metadatos

#### 6. **Servicios de Aplicaci√≥n**
- `EmbeddingsServiceV2`: `top_k=10` por defecto
- `ChatServiceV2`: L√≠mite de contexto aumentado a 12000 caracteres
- `chunk_text()`: Nuevos defaults (1000/150)

---

## üîÑ Migraci√≥n de Base de Datos

### Script de Migraci√≥n

Se incluye un script para actualizar bases de datos existentes:

```bash
python scripts/migrate_embeddings_add_metadata.py
```

**El script:**
1. ‚úÖ Verifica si las columnas ya existen
2. ‚ûï Agrega columnas de metadatos si faltan
3. üìä Crea √≠ndices para mejor rendimiento
4. üìà Muestra estad√≠sticas de la tabla

**Nota:** Los chunks existentes tendr√°n metadatos NULL hasta que se re-indexen.

---

## üìä Comparaci√≥n: Antes vs Ahora

| Aspecto | Antes | Ahora | Mejora |
|---------|-------|-------|--------|
| **Chunks retornados** | 5 | 10 | +100% |
| **Tama√±o de chunk** | 600 chars | 1000 chars | +67% |
| **Overlap** | 100 chars | 150 chars | +50% |
| **Contexto total** | ~3000 chars | ~10000 chars | +233% |
| **Metadatos** | ‚ùå No | ‚úÖ S√≠ | Nuevo |
| **Filtrado** | Solo por file_id | file_id + p√°gina + tipo | Mejorado |

---

## üß™ Pruebas Recomendadas

### 1. Re-indexar PDFs Existentes

```python
# Desde Streamlit o API
POST /api/v1/embeddings/index/{file_id}
```

Esto generar√° chunks con:
- Nuevo tama√±o (1000 chars)
- Metadatos completos
- Mejor cobertura

### 2. Probar B√∫squedas

```python
# B√∫squeda con m√°s contexto
GET /api/v1/embeddings/search?q=tu_consulta&file_id=1&top_k=10
```

### 3. Verificar Metadatos

```sql
SELECT 
    chunk_index, 
    page_number, 
    section_type, 
    file_name,
    LEFT(content, 50) as preview
FROM document_chunks
WHERE file_id = 1
LIMIT 10;
```

---

## üéØ Casos de Uso Mejorados

### 1. **B√∫squeda por P√°gina Espec√≠fica**
```python
# Futuro: Filtrar por rango de p√°ginas
results = await embeddings.search_similar(
    query="explicaci√≥n de decoradores",
    file_id="1",
    page_range=(10, 20)  # P√°ginas 10-20
)
```

### 2. **Filtrado por Tipo de Secci√≥n**
```python
# Futuro: Solo buscar en cap√≠tulos
results = await embeddings.search_similar(
    query="arquitectura hexagonal",
    file_id="1",
    section_type="chapter"
)
```

### 3. **Contexto Enriquecido**
Los resultados ahora incluyen:
```python
{
    "text": "contenido del chunk...",
    "similarity": 0.95,
    "page_number": 42,
    "section_type": "chapter",
    "file_name": "fluent_python.pdf"
}
```

---

## ‚ö†Ô∏è Consideraciones

### Compatibilidad Retroactiva
‚úÖ **Totalmente compatible**
- Los chunks antiguos funcionar√°n (metadatos NULL)
- No se requiere re-indexar inmediatamente
- La migraci√≥n es no destructiva

### Rendimiento
- **Indexaci√≥n:** ~10-15% m√°s lenta (chunks m√°s grandes)
- **B√∫squeda:** Similar o mejor (√≠ndices optimizados)
- **Almacenamiento:** +5-10% por metadatos

### Recomendaciones
1. ‚úÖ Ejecutar migraci√≥n en horario de bajo tr√°fico
2. ‚úÖ Re-indexar PDFs importantes primero
3. ‚úÖ Monitorear uso de tokens de Gemini API
4. ‚úÖ Ajustar `max_search_results` seg√∫n necesidad

---

## üîß Configuraci√≥n Avanzada

### Variables de Entorno

```bash
# .env
EMBEDDING_CHUNK_SIZE=1000
EMBEDDING_CHUNK_OVERLAP=150
MAX_SEARCH_RESULTS=10
```

### Ajustes Finos

Para hardware limitado:
```python
# settings.py
embedding_chunk_size = 800  # Reducir si hay problemas de memoria
max_search_results = 8      # Reducir para menos tokens
```

Para mejor calidad:
```python
# settings.py
embedding_chunk_size = 1200  # Aumentar para m√°s contexto
max_search_results = 15      # Aumentar para mayor cobertura
```

---

## üìö Referencias

- **Gemini API:** `text-embedding-004` (768 dims)
- **pgvector:** Extensi√≥n de PostgreSQL para vectores
- **Arquitectura:** Hexagonal (Ports & Adapters)
- **Tipado:** Python 3.12+ con mypy --strict

---

## üéâ Resultado Final

El sistema RAG ahora proporciona:
- ‚úÖ **M√°s contexto** (10 chunks vs 5)
- ‚úÖ **Mejor coherencia** (chunks m√°s grandes)
- ‚úÖ **Filtrado inteligente** (metadatos)
- ‚úÖ **Trazabilidad** (p√°gina, tipo, archivo)
- ‚úÖ **Arquitectura limpia** (sin romper SOLID)
- ‚úÖ **Tipado estricto** (mypy compatible)

**Todo listo para producci√≥n sin romper compatibilidad con Kimi ni SQLite.** üöÄ
